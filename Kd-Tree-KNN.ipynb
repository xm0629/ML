{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    '''\n",
    "    首先实现一个节点类表示 kd\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, data, lchild=None, rchild=None):\n",
    "        self.data = data\n",
    "        self.lchild = lchild\n",
    "        self.rchild = rchild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KdTree:\n",
    "    \"\"\"\n",
    "        KdTree 类的实现\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.kdTree = None\n",
    "\n",
    "    def create(self, dataSet, depth):   #创建kd树，返回根结点\n",
    "        if (len(dataSet) > 0):\n",
    "            m, n = np.shape(dataSet)    #求出样本行，列\n",
    "            midIndex = int(m / 2) #中间数的索引位置\n",
    "            axis = depth % n    #判断以哪个轴划分数据\n",
    "            sortedDataSet = self.sort(dataSet, axis) #进行排序\n",
    "            node = Node(sortedDataSet[midIndex]) #将节点数据域设置为中位数，具体参考下书本\n",
    "            leftDataSet = sortedDataSet[: midIndex] #将中位数的左边创建2改副本\n",
    "            rightDataSet = sortedDataSet[midIndex+1 :]\n",
    "            print(leftDataSet)\n",
    "            print(rightDataSet)\n",
    "            node.lchild = self.create(leftDataSet, depth+1) #将中位数左边样本传入来递归创建树\n",
    "            node.rchild = self.create(rightDataSet, depth+1)\n",
    "            return node\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def sort(self, dataSet, axis):  #采用冒泡排序，利用aixs作为轴进行划分\n",
    "        sortDataSet = dataSet[:]    #由于不能破坏原样本，此处建立一个副本\n",
    "        m, n = np.shape(sortDataSet)\n",
    "        for i in range(m):\n",
    "            for j in range(0, m - i - 1):\n",
    "                if (sortDataSet[j][axis] > sortDataSet[j+1][axis]):\n",
    "                    temp = sortDataSet[j]\n",
    "                    sortDataSet[j] = sortDataSet[j+1]\n",
    "                    sortDataSet[j+1] = temp\n",
    "        print(sortDataSet)\n",
    "        return sortDataSet\n",
    "\n",
    "    def preOrder(self, node):\n",
    "        if node != None:\n",
    "            print(\"tttt->%s\" % node.data)\n",
    "            self.preOrder(node.lchild)\n",
    "            self.preOrder(node.rchild)\n",
    "\n",
    "    def search(self, tree, x):\n",
    "        self.nearestPoint = None    #保存最近的点\n",
    "        self.nearestValue = 0   #保存最近的值\n",
    "        def travel(node, depth = 0):    #递归搜索\n",
    "            if node != None:    #递归终止条件\n",
    "                n = len(x)  #特征数\n",
    "                axis = depth % n    #计算轴\n",
    "                if x[axis] < node.data[axis]:   #如果数据小于结点，则往左结点找\n",
    "                    travel(node.lchild, depth+1)\n",
    "                else:\n",
    "                    travel(node.rchild, depth+1)\n",
    "\n",
    "                #以下是递归完毕后，往父结点方向回朔\n",
    "                distNodeAndX = self.dist(x, node.data)  #目标和节点的距离判断\n",
    "                if (self.nearestPoint == None): #确定当前点，更新最近的点和最近的值\n",
    "                    self.nearestPoint = node.data\n",
    "                    self.nearestValue = distNodeAndX\n",
    "                elif (self.nearestValue > distNodeAndX):\n",
    "                    self.nearestPoint = node.data\n",
    "                    self.nearestValue = distNodeAndX\n",
    "\n",
    "                print(node.data, depth, self.nearestValue, node.data[axis], x[axis])\n",
    "                if (abs(x[axis] - node.data[axis]) <= self.nearestValue):  #确定是否需要去子节点的区域去找（圆的判断）\n",
    "                    if x[axis] < node.data[axis]:\n",
    "                        travel(node.rchild, depth+1)\n",
    "                    else:\n",
    "                        travel(node.lchild, depth + 1)\n",
    "        travel(tree)\n",
    "        return self.nearestPoint\n",
    "\n",
    "    def dist(self, x1, x2): #欧式距离的计算\n",
    "        return ((np.array(x1) - np.array(x2)) ** 2).sum() ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 3], [4, 7], [5, 4], [7, 2], [8, 1], [9, 6]]\n",
      "[[2, 3], [4, 7], [5, 4]]\n",
      "[[8, 1], [9, 6]]\n",
      "[[2, 3], [5, 4], [4, 7]]\n",
      "[[2, 3]]\n",
      "[[4, 7]]\n",
      "[[2, 3]]\n",
      "[]\n",
      "[]\n",
      "[[4, 7]]\n",
      "[]\n",
      "[]\n",
      "[[8, 1], [9, 6]]\n",
      "[[8, 1]]\n",
      "[]\n",
      "[[8, 1]]\n",
      "[]\n",
      "[]\n",
      "tttt->[7, 2]\n",
      "tttt->[5, 4]\n",
      "tttt->[2, 3]\n",
      "tttt->[4, 7]\n",
      "tttt->[9, 6]\n",
      "tttt->[8, 1]\n",
      "[2, 3] 2 3.0 2 5\n",
      "[5, 4] 1 1.0 4 3\n",
      "[4, 7] 2 1.0 4 5\n",
      "[7, 2] 0 1.0 7 5\n",
      "[5, 4]\n"
     ]
    }
   ],
   "source": [
    "dataSet = [[2, 3],\n",
    "           [5, 4],\n",
    "           [9, 6],\n",
    "           [4, 7],\n",
    "           [8, 1],\n",
    "           [7, 2]]\n",
    "x = [5, 3]\n",
    "kdtree = KdTree()\n",
    "tree = kdtree.create(dataSet, 0)\n",
    "kdtree.preOrder(tree)\n",
    "print(kdtree.search(tree, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.neighbors.kd_tree as kdtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module sklearn.neighbors.kd_tree in sklearn.neighbors:\n",
      "\n",
      "NAME\n",
      "    sklearn.neighbors.kd_tree\n",
      "\n",
      "CLASSES\n",
      "    BinaryTree(builtins.object)\n",
      "        KDTree\n",
      "    \n",
      "    class KDTree(BinaryTree)\n",
      "     |  KDTree for fast generalized N-point problems\n",
      "     |  \n",
      "     |  KDTree(X, leaf_size=40, metric='minkowski', \\**kwargs)\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  X : array-like, shape = [n_samples, n_features]\n",
      "     |      n_samples is the number of points in the data set, and\n",
      "     |      n_features is the dimension of the parameter space.\n",
      "     |      Note: if X is a C-contiguous array of doubles then data will\n",
      "     |      not be copied. Otherwise, an internal copy will be made.\n",
      "     |  \n",
      "     |  leaf_size : positive integer (default = 40)\n",
      "     |      Number of points at which to switch to brute-force. Changing\n",
      "     |      leaf_size will not affect the results of a query, but can\n",
      "     |      significantly impact the speed of a query and the memory required\n",
      "     |      to store the constructed tree.  The amount of memory needed to\n",
      "     |      store the tree scales as approximately n_samples / leaf_size.\n",
      "     |      For a specified ``leaf_size``, a leaf node is guaranteed to\n",
      "     |      satisfy ``leaf_size <= n_points <= 2 * leaf_size``, except in\n",
      "     |      the case that ``n_samples < leaf_size``.\n",
      "     |  \n",
      "     |  metric : string or DistanceMetric object\n",
      "     |      the distance metric to use for the tree.  Default='minkowski'\n",
      "     |      with p=2 (that is, a euclidean metric). See the documentation\n",
      "     |      of the DistanceMetric class for a list of available metrics.\n",
      "     |      kd_tree.valid_metrics gives a list of the metrics which\n",
      "     |      are valid for KDTree.\n",
      "     |  \n",
      "     |  Additional keywords are passed to the distance metric class.\n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  data : np.ndarray\n",
      "     |      The training data\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  Query for k-nearest neighbors\n",
      "     |  \n",
      "     |      >>> import numpy as np\n",
      "     |      >>> np.random.seed(0)\n",
      "     |      >>> X = np.random.random((10, 3))  # 10 points in 3 dimensions\n",
      "     |      >>> tree = KDTree(X, leaf_size=2)              # doctest: +SKIP\n",
      "     |      >>> dist, ind = tree.query([X[0]], k=3)                # doctest: +SKIP\n",
      "     |      >>> print(ind)  # indices of 3 closest neighbors\n",
      "     |      [0 3 1]\n",
      "     |      >>> print(dist)  # distances to 3 closest neighbors\n",
      "     |      [ 0.          0.19662693  0.29473397]\n",
      "     |  \n",
      "     |  Pickle and Unpickle a tree.  Note that the state of the tree is saved in the\n",
      "     |  pickle operation: the tree needs not be rebuilt upon unpickling.\n",
      "     |  \n",
      "     |      >>> import numpy as np\n",
      "     |      >>> import pickle\n",
      "     |      >>> np.random.seed(0)\n",
      "     |      >>> X = np.random.random((10, 3))  # 10 points in 3 dimensions\n",
      "     |      >>> tree = KDTree(X, leaf_size=2)        # doctest: +SKIP\n",
      "     |      >>> s = pickle.dumps(tree)                     # doctest: +SKIP\n",
      "     |      >>> tree_copy = pickle.loads(s)                # doctest: +SKIP\n",
      "     |      >>> dist, ind = tree_copy.query(X[0], k=3)     # doctest: +SKIP\n",
      "     |      >>> print(ind)  # indices of 3 closest neighbors\n",
      "     |      [0 3 1]\n",
      "     |      >>> print(dist)  # distances to 3 closest neighbors\n",
      "     |      [ 0.          0.19662693  0.29473397]\n",
      "     |  \n",
      "     |  Query for neighbors within a given radius\n",
      "     |  \n",
      "     |      >>> import numpy as np\n",
      "     |      >>> np.random.seed(0)\n",
      "     |      >>> X = np.random.random((10, 3))  # 10 points in 3 dimensions\n",
      "     |      >>> tree = KDTree(X, leaf_size=2)     # doctest: +SKIP\n",
      "     |      >>> print(tree.query_radius(X[0], r=0.3, count_only=True))\n",
      "     |      3\n",
      "     |      >>> ind = tree.query_radius(X[0], r=0.3)  # doctest: +SKIP\n",
      "     |      >>> print(ind)  # indices of neighbors within distance 0.3\n",
      "     |      [3 0 1]\n",
      "     |  \n",
      "     |  \n",
      "     |  Compute a gaussian kernel density estimate:\n",
      "     |  \n",
      "     |      >>> import numpy as np\n",
      "     |      >>> np.random.seed(1)\n",
      "     |      >>> X = np.random.random((100, 3))\n",
      "     |      >>> tree = KDTree(X)                # doctest: +SKIP\n",
      "     |      >>> tree.kernel_density(X[:3], h=0.1, kernel='gaussian')\n",
      "     |      array([ 6.94114649,  7.83281226,  7.2071716 ])\n",
      "     |  \n",
      "     |  Compute a two-point auto-correlation function\n",
      "     |  \n",
      "     |      >>> import numpy as np\n",
      "     |      >>> np.random.seed(0)\n",
      "     |      >>> X = np.random.random((30, 3))\n",
      "     |      >>> r = np.linspace(0, 1, 5)\n",
      "     |      >>> tree = KDTree(X)                # doctest: +SKIP\n",
      "     |      >>> tree.two_point_correlation(X, r)\n",
      "     |      array([ 30,  62, 278, 580, 820])\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      KDTree\n",
      "     |      BinaryTree\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __pyx_vtable__ = <capsule object NULL>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from BinaryTree:\n",
      "     |  \n",
      "     |  __getstate__(...)\n",
      "     |      get state for pickling\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      reduce method used for pickling\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |      set state for pickling\n",
      "     |  \n",
      "     |  get_arrays(...)\n",
      "     |  \n",
      "     |  get_n_calls(...)\n",
      "     |  \n",
      "     |  get_tree_stats(...)\n",
      "     |  \n",
      "     |  kernel_density(...)\n",
      "     |      kernel_density(self, X, h, kernel='gaussian', atol=0, rtol=1E-8,\n",
      "     |                     breadth_first=True, return_log=False)\n",
      "     |      \n",
      "     |      Compute the kernel density estimate at points X with the given kernel,\n",
      "     |      using the distance metric specified at tree creation.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array_like\n",
      "     |          An array of points to query.  Last dimension should match dimension\n",
      "     |          of training data.\n",
      "     |      h : float\n",
      "     |          the bandwidth of the kernel\n",
      "     |      kernel : string\n",
      "     |          specify the kernel to use.  Options are\n",
      "     |          - 'gaussian'\n",
      "     |          - 'tophat'\n",
      "     |          - 'epanechnikov'\n",
      "     |          - 'exponential'\n",
      "     |          - 'linear'\n",
      "     |          - 'cosine'\n",
      "     |          Default is kernel = 'gaussian'\n",
      "     |      atol, rtol : float (default = 0)\n",
      "     |          Specify the desired relative and absolute tolerance of the result.\n",
      "     |          If the true result is K_true, then the returned result K_ret\n",
      "     |          satisfies ``abs(K_true - K_ret) < atol + rtol * K_ret``\n",
      "     |          The default is zero (i.e. machine precision) for both.\n",
      "     |      breadth_first : boolean (default = False)\n",
      "     |          if True, use a breadth-first search.  If False (default) use a\n",
      "     |          depth-first search.  Breadth-first is generally faster for\n",
      "     |          compact kernels and/or high tolerances.\n",
      "     |      return_log : boolean (default = False)\n",
      "     |          return the logarithm of the result.  This can be more accurate\n",
      "     |          than returning the result itself for narrow kernels.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      density : ndarray\n",
      "     |          The array of (log)-density evaluations, shape = X.shape[:-1]\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Compute a gaussian kernel density estimate:\n",
      "     |      \n",
      "     |      >>> import numpy as np\n",
      "     |      >>> np.random.seed(1)\n",
      "     |      >>> X = np.random.random((100, 3))\n",
      "     |      >>> tree = BinaryTree(X)           # doctest: +SKIP\n",
      "     |      >>> tree.kernel_density(X[:3], h=0.1, kernel='gaussian')\n",
      "     |      array([ 6.94114649,  7.83281226,  7.2071716 ])\n",
      "     |  \n",
      "     |  query(...)\n",
      "     |      query(X, k=1, return_distance=True,\n",
      "     |            dualtree=False, breadth_first=False)\n",
      "     |      \n",
      "     |      query the tree for the k nearest neighbors\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like, last dimension self.dim\n",
      "     |          An array of points to query\n",
      "     |      k : integer  (default = 1)\n",
      "     |          The number of nearest neighbors to return\n",
      "     |      return_distance : boolean (default = True)\n",
      "     |          if True, return a tuple (d, i) of distances and indices\n",
      "     |          if False, return array i\n",
      "     |      dualtree : boolean (default = False)\n",
      "     |          if True, use the dual tree formalism for the query: a tree is\n",
      "     |          built for the query points, and the pair of trees is used to\n",
      "     |          efficiently search this space.  This can lead to better\n",
      "     |          performance as the number of points grows large.\n",
      "     |      breadth_first : boolean (default = False)\n",
      "     |          if True, then query the nodes in a breadth-first manner.\n",
      "     |          Otherwise, query the nodes in a depth-first manner.\n",
      "     |      sort_results : boolean (default = True)\n",
      "     |          if True, then distances and indices of each point are sorted\n",
      "     |          on return, so that the first column contains the closest points.\n",
      "     |          Otherwise, neighbors are returned in an arbitrary order.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      i    : if return_distance == False\n",
      "     |      (d,i) : if return_distance == True\n",
      "     |      \n",
      "     |      d : array of doubles - shape: x.shape[:-1] + (k,)\n",
      "     |          each entry gives the list of distances to the\n",
      "     |          neighbors of the corresponding point\n",
      "     |      \n",
      "     |      i : array of integers - shape: x.shape[:-1] + (k,)\n",
      "     |          each entry gives the list of indices of\n",
      "     |          neighbors of the corresponding point\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Query for k-nearest neighbors\n",
      "     |      \n",
      "     |          >>> import numpy as np\n",
      "     |          >>> np.random.seed(0)\n",
      "     |          >>> X = np.random.random((10, 3))  # 10 points in 3 dimensions\n",
      "     |          >>> tree = BinaryTree(X, leaf_size=2)    # doctest: +SKIP\n",
      "     |          >>> dist, ind = tree.query(X[0], k=3)    # doctest: +SKIP\n",
      "     |          >>> print(ind)  # indices of 3 closest neighbors\n",
      "     |          [0 3 1]\n",
      "     |          >>> print(dist)  # distances to 3 closest neighbors\n",
      "     |          [ 0.          0.19662693  0.29473397]\n",
      "     |  \n",
      "     |  query_radius(...)\n",
      "     |      query_radius(self, X, r, count_only = False):\n",
      "     |      \n",
      "     |      query the tree for neighbors within a radius r\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like, last dimension self.dim\n",
      "     |          An array of points to query\n",
      "     |      r : distance within which neighbors are returned\n",
      "     |          r can be a single value, or an array of values of shape\n",
      "     |          x.shape[:-1] if different radii are desired for each point.\n",
      "     |      return_distance : boolean (default = False)\n",
      "     |          if True,  return distances to neighbors of each point\n",
      "     |          if False, return only neighbors\n",
      "     |          Note that unlike the query() method, setting return_distance=True\n",
      "     |          here adds to the computation time.  Not all distances need to be\n",
      "     |          calculated explicitly for return_distance=False.  Results are\n",
      "     |          not sorted by default: see ``sort_results`` keyword.\n",
      "     |      count_only : boolean (default = False)\n",
      "     |          if True,  return only the count of points within distance r\n",
      "     |          if False, return the indices of all points within distance r\n",
      "     |          If return_distance==True, setting count_only=True will\n",
      "     |          result in an error.\n",
      "     |      sort_results : boolean (default = False)\n",
      "     |          if True, the distances and indices will be sorted before being\n",
      "     |          returned.  If False, the results will not be sorted.  If\n",
      "     |          return_distance == False, setting sort_results = True will\n",
      "     |          result in an error.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      count       : if count_only == True\n",
      "     |      ind         : if count_only == False and return_distance == False\n",
      "     |      (ind, dist) : if count_only == False and return_distance == True\n",
      "     |      \n",
      "     |      count : array of integers, shape = X.shape[:-1]\n",
      "     |          each entry gives the number of neighbors within\n",
      "     |          a distance r of the corresponding point.\n",
      "     |      \n",
      "     |      ind : array of objects, shape = X.shape[:-1]\n",
      "     |          each element is a numpy integer array listing the indices of\n",
      "     |          neighbors of the corresponding point.  Note that unlike\n",
      "     |          the results of a k-neighbors query, the returned neighbors\n",
      "     |          are not sorted by distance by default.\n",
      "     |      \n",
      "     |      dist : array of objects, shape = X.shape[:-1]\n",
      "     |          each element is a numpy double array\n",
      "     |          listing the distances corresponding to indices in i.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Query for neighbors in a given radius\n",
      "     |      \n",
      "     |      >>> import numpy as np\n",
      "     |      >>> np.random.seed(0)\n",
      "     |      >>> X = np.random.random((10, 3))  # 10 points in 3 dimensions\n",
      "     |      >>> tree = BinaryTree(X, leaf_size=2)     # doctest: +SKIP\n",
      "     |      >>> print(tree.query_radius(X[0], r=0.3, count_only=True))\n",
      "     |      3\n",
      "     |      >>> ind = tree.query_radius(X[0], r=0.3)  # doctest: +SKIP\n",
      "     |      >>> print(ind)  # indices of neighbors within distance 0.3\n",
      "     |      [3 0 1]\n",
      "     |  \n",
      "     |  reset_n_calls(...)\n",
      "     |  \n",
      "     |  two_point_correlation(...)\n",
      "     |      Compute the two-point correlation function\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array_like\n",
      "     |          An array of points to query.  Last dimension should match dimension\n",
      "     |          of training data.\n",
      "     |      r : array_like\n",
      "     |          A one-dimensional array of distances\n",
      "     |      dualtree : boolean (default = False)\n",
      "     |          If true, use a dualtree algorithm.  Otherwise, use a single-tree\n",
      "     |          algorithm.  Dual tree algorithms can have better scaling for\n",
      "     |          large N.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      counts : ndarray\n",
      "     |          counts[i] contains the number of pairs of points with distance\n",
      "     |          less than or equal to r[i]\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Compute the two-point autocorrelation function of X:\n",
      "     |      \n",
      "     |      >>> import numpy as np\n",
      "     |      >>> np.random.seed(0)\n",
      "     |      >>> X = np.random.random((30, 3))\n",
      "     |      >>> r = np.linspace(0, 1, 5)\n",
      "     |      >>> tree = BinaryTree(X)     # doctest: +SKIP\n",
      "     |      >>> tree.two_point_correlation(X, r)\n",
      "     |      array([ 30,  62, 278, 580, 820])\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from BinaryTree:\n",
      "     |  \n",
      "     |  data\n",
      "     |  \n",
      "     |  idx_array\n",
      "     |  \n",
      "     |  node_bounds\n",
      "     |  \n",
      "     |  node_data\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from BinaryTree:\n",
      "     |  \n",
      "     |  valid_metrics = ['euclidean', 'l2', 'minkowski', 'p', 'manhattan', 'ci...\n",
      "\n",
      "DATA\n",
      "    __all__ = ['KDTree']\n",
      "    __test__ = {'BinaryTree.kernel_density (line 1504)': \"\\n        kernel...\n",
      "\n",
      "FILE\n",
      "    /usr/local/lib/python3.6/dist-packages/sklearn/neighbors/kd_tree.cpython-36m-x86_64-linux-gnu.so\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(kdtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
